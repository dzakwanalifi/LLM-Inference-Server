[project]
# Metadata dasar untuk proyek Anda
name = "llm-inference-server"
version = "0.1.0"
description = "A production-ready FastAPI server for local LLM inference."
authors = [
    { name = "Dzakwan Alifi", email = "mdzakwanalifi@gmail.com" },
]
requires-python = ">=3.11"

# Dependensi utama aplikasi
dependencies = [
    "fastapi",
    "uvicorn[standard]",
    "llama-cpp-python",
    "python-dotenv",
    "structlog",
    "slowapi",
    "gunicorn",
]

# TAMBAHKAN BAGIAN INI
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
# Konfigurasi spesifik untuk uv jika diperlukan (opsional)
# preview = true